<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" type="text/css" href="mlstarter.css">
</head>
<body>

<h2>BASIC WORKFLOWS</h2>
<h3></h3>
<h3>get the latest info on new networks:</h3>
<p>-> facebook/twitter (Gene, YannLeCunn)<br>
-> NVIDIA newsletter<br>
-> github discussions (issues sections in neural network repos)</p>

<h3>get the networks/models:</h3>
<p>-> github repos</p>

<h3>types of main frameworks:</h3>
<p>-><a href="https://www.tensorflow.org/" target="_self">tensorflow</a>: machine learning library, comes in TensorFlow Lite for mobile as well, python based (Google)<br>
-><a href="http://torch.ch/" target="_self">torch:</a>machine learning library/framework, LUA based<br>
-> NVIDIA libraries <a href="https://developer.nvidia.com/cuda-toolkit" target="_self">CUDA</a> / <a href="https://developer.nvidia.com/cudnn" target="_self">cuDNN</a> <a href="https://developer.nvidia.com/developer-program" target="_self">(developer account necessary)</a><br>
-> caffe? caffe2go? facebook?<br>
-> lots of extra libraries necessary for installation</p>

<h3>train/run:</h3>
<p>-> local machine (cheap, slow, takes up a lot of CPU/GPU) <br>
-> remote servers (AWS, packet, google cloud, â€¦): CPU vs GPU (costs/speed), everything from terminal via ssh/mosh <br>
-> <a href="http://docker.io" target="_self">docker:</a> encapsulates/containerises your trained model&framework, can save it <br>locally or to the cloud, can easily be shared, backed up, saves a lot of time for installation, good with remote servers, port <br>forwarding necessary in live installations, sudo apt-get <a href="http://docker.io" target="_self">docker.io</a>for ubuntu;<br>
<a href="https://github.com/jakeelwes/dl-docker" target="_self">docker image deep learning toolset</a>
-> lego-blocking with python (2.7 rather than 3)</p>

<p><a id="prevLink" href='exin.html'></a> &#8194; <a id="nextLink" href='hon.html'></a></p>

<script src="ml.js"></script>

<p><a href="index.html" target="_self">topics</a></p>

</body>
</html>